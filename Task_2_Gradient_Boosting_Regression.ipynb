{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n",
      "Best Model Performance:\n",
      "Best Parameters: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 300}\n",
      "Mean Squared Error (MSE): 0.00028630592247340923\n",
      "R-squared (RÂ²) Score: 0.9986954181455355\n",
      "Adjusted R-squared: 0.9928972765701379\n",
      "Explained Variance Score: 0.9987221805558546\n",
      "Mean Absolute Percentage Error (MAPE): 0.0018312578781679181\n",
      "GridSearchCV fit status:\n",
      "{'mean_fit_time': array([0.20013309, 0.94580754, 1.82279555, 0.90624475, 1.47040391,\n",
      "       2.15989288, 0.788891  , 1.45577359, 2.15956012, 0.77958361,\n",
      "       1.48137323, 2.11468132, 0.79986183, 1.4727308 , 1.72737877,\n",
      "       0.78224134, 0.67818435, 1.09008686, 0.27825832, 1.25597906,\n",
      "       2.06481393, 0.76562134, 1.46408534, 2.32212671, 0.83609811,\n",
      "       1.56215692, 2.29619519, 1.21574926, 2.50368142, 2.65989653,\n",
      "       1.3146592 , 1.52433141, 2.68620928, 0.87648924, 2.0724167 ,\n",
      "       2.9899772 , 1.17558138, 2.10026185, 3.71587332, 1.30259236,\n",
      "       2.48583849, 3.22661146, 0.75651884, 2.27337829, 3.05187345,\n",
      "       1.07634799, 2.11796618, 3.01647751, 1.08733598, 2.06481385,\n",
      "       2.37730829, 1.05783963, 1.23802042, 1.65624094, 0.65358933,\n",
      "       2.32478682, 3.81205169, 1.28689345, 2.50663233, 3.78720856,\n",
      "       1.18017991, 2.36434841, 3.0319771 , 0.92219965, 2.30101116,\n",
      "       3.82095202, 1.29672678, 2.40298994, 3.50765045, 1.18194135,\n",
      "       2.22118632, 2.65527026, 1.12971203, 1.17054915, 2.33060781,\n",
      "       1.09216785, 2.03799208, 3.10522437, 1.06067149, 1.98721393,\n",
      "       2.91582243, 0.82337054, 1.49798258, 2.0713683 , 0.82752657,\n",
      "       1.16585239, 0.99284085, 0.25206757, 0.68490537, 1.97993652,\n",
      "       0.80437239, 1.43991502, 2.22012234, 0.86676224, 1.58487837,\n",
      "       2.11178072, 0.76883801, 1.41870205, 2.07694626, 0.81180946,\n",
      "       1.46756156, 1.74111748, 0.80420963, 1.06411076, 1.81586401,\n",
      "       0.79823613, 1.35926755, 1.96534467, 1.15205129, 2.23148775,\n",
      "       3.15486121, 1.15027603, 2.2137804 , 2.6626486 , 1.00170326,\n",
      "       1.28259412, 1.78489598, 0.52733103, 1.7235171 , 2.81439543,\n",
      "       1.07464925, 1.95145845, 2.83099747, 1.11350894, 1.89587871,\n",
      "       2.68035793, 0.99230552, 1.76558113, 1.40439526, 0.33123326,\n",
      "       0.83858379, 2.27132233, 0.98686806, 1.88217211, 2.60008232,\n",
      "       1.37788431, 2.46979435, 3.51776425, 1.23134287, 2.48872781,\n",
      "       3.26041985, 0.90012193, 2.23084299, 3.61052998, 1.32372848,\n",
      "       2.42559958, 3.35571901, 1.2697823 , 2.25681726, 2.67684682,\n",
      "       1.02051155, 1.47345646, 2.88656584, 1.120332  , 2.16879956,\n",
      "       3.02691929, 1.16162435, 2.17026059, 3.08317916, 1.0697523 ,\n",
      "       2.02716009, 1.87544791, 0.39526558, 0.45771114, 1.66323002,\n",
      "       0.85571432, 1.47059957, 2.09518607, 0.80448794, 1.46203065,\n",
      "       2.00906293, 0.77262759, 1.50246374, 2.15666358, 0.82740792,\n",
      "       1.40126061, 1.75810885, 0.74171527, 1.00409301, 0.8270692 ,\n",
      "       0.18618981, 0.91004801, 1.8186241 , 0.74338929, 1.38916643,\n",
      "       2.06044014, 0.80553357, 1.43229095, 1.90376727, 1.17313949,\n",
      "       1.87940192, 2.10992853, 1.13995949, 1.86430279, 1.91006025,\n",
      "       0.97769149, 1.90118027, 2.5229001 , 1.05700636, 2.00121673,\n",
      "       2.96756999, 1.08424703, 2.05467661, 2.7384855 , 1.01744644,\n",
      "       1.88420884, 1.42540367, 0.41412719, 0.62438424, 2.19574428,\n",
      "       0.94594908, 1.73985783, 2.64024981, 0.99530745, 1.78033034,\n",
      "       2.65425356, 1.29812479, 2.10564399, 2.27416817, 1.29522498,\n",
      "       1.31342252, 1.59553965, 0.69902054, 1.99293335, 2.20870113,\n",
      "       1.22343222, 2.96452498, 4.38057137, 1.83369009, 2.95616341,\n",
      "       2.26260122, 0.61068384, 0.98726765, 2.82469289, 1.07208244,\n",
      "       2.03309274, 2.90681195, 1.09741068, 2.0106744 , 2.95834247,\n",
      "       1.04390383, 1.93911219, 1.88072069]), 'std_fit_time': array([0.00523709, 0.06443156, 0.2489273 , 0.05949248, 0.00261761,\n",
      "       0.03048265, 0.00293661, 0.03905615, 0.01793993, 0.02523452,\n",
      "       0.00094032, 0.01222227, 0.01547157, 0.01739524, 0.12274142,\n",
      "       0.04926829, 0.08923706, 0.09442029, 0.07864469, 0.12134858,\n",
      "       0.00855425, 0.02510156, 0.04093505, 0.0162925 , 0.03431934,\n",
      "       0.08326082, 0.11162273, 0.06496219, 0.18192488, 0.04152838,\n",
      "       0.19562847, 0.02639236, 0.22048138, 0.21867858, 0.02822645,\n",
      "       0.07096636, 0.0602261 , 0.02335184, 0.05868006, 0.01509248,\n",
      "       0.22317815, 0.16061447, 0.0082752 , 0.0483143 , 0.04575387,\n",
      "       0.03768083, 0.02561823, 0.0041    , 0.02791152, 0.0498691 ,\n",
      "       0.26008529, 0.0332214 , 0.24178649, 0.19392104, 0.02360644,\n",
      "       0.12775418, 0.07610971, 0.03201247, 0.00632422, 0.074226  ,\n",
      "       0.03053749, 0.09011542, 0.03753577, 0.21045788, 0.06659712,\n",
      "       0.126448  , 0.08642822, 0.05254795, 0.03795647, 0.05765834,\n",
      "       0.04148598, 0.29620851, 0.02033581, 0.1153516 , 0.28303868,\n",
      "       0.12352083, 0.09631726, 0.08582588, 0.02749095, 0.07163959,\n",
      "       0.12199832, 0.02272423, 0.07191127, 0.10816021, 0.04969647,\n",
      "       0.10313198, 0.03043009, 0.08265851, 0.06250169, 0.20218625,\n",
      "       0.04011938, 0.04917973, 0.03918759, 0.0898733 , 0.08376108,\n",
      "       0.08912228, 0.04823091, 0.02382659, 0.07141928, 0.01005178,\n",
      "       0.02550145, 0.10081087, 0.02937823, 0.07795795, 0.11298404,\n",
      "       0.02542047, 0.04990664, 0.03151868, 0.04555822, 0.11600316,\n",
      "       0.04083009, 0.04378937, 0.04109298, 0.31395108, 0.05690928,\n",
      "       0.1539121 , 0.13533234, 0.14036686, 0.26899054, 0.14101411,\n",
      "       0.02387728, 0.12782587, 0.01743482, 0.06371978, 0.03651446,\n",
      "       0.11207593, 0.03602836, 0.08311045, 0.09403137, 0.14087344,\n",
      "       0.23994861, 0.18090068, 0.0058343 , 0.03410656, 0.0150307 ,\n",
      "       0.03930962, 0.03766096, 0.19281105, 0.01782439, 0.09087138,\n",
      "       0.0512277 , 0.03980561, 0.10473821, 0.08346791, 0.09942728,\n",
      "       0.04580111, 0.09383598, 0.0784035 , 0.05639052, 0.07011995,\n",
      "       0.09708736, 0.02827108, 0.32442025, 0.04309811, 0.07224557,\n",
      "       0.03828122, 0.03053693, 0.0087857 , 0.08416788, 0.03770897,\n",
      "       0.10470495, 0.10029758, 0.13156205, 0.08044876, 0.2055436 ,\n",
      "       0.04519805, 0.03465359, 0.09518337, 0.02945849, 0.02156393,\n",
      "       0.09118516, 0.02748734, 0.08258125, 0.10516794, 0.0074465 ,\n",
      "       0.03246552, 0.09641721, 0.02656521, 0.18542254, 0.12102849,\n",
      "       0.00611484, 0.17246344, 0.04314065, 0.04644761, 0.07170339,\n",
      "       0.01269273, 0.02909092, 0.02956262, 0.00352025, 0.07847089,\n",
      "       0.02317852, 0.08875823, 0.04638102, 0.12938018, 0.0797772 ,\n",
      "       0.07802841, 0.08054947, 0.23245564, 0.10666972, 0.06387802,\n",
      "       0.04734457, 0.1059312 , 0.05235562, 0.12472432, 0.05670875,\n",
      "       0.04645538, 0.07837925, 0.17097237, 0.10273245, 0.07610278,\n",
      "       0.04345162, 0.02486258, 0.02690244, 0.04819858, 0.05609095,\n",
      "       0.11948734, 0.03967389, 0.11535022, 0.04732942, 0.07524665,\n",
      "       0.01655747, 0.08644355, 0.33555402, 0.07777077, 0.07965184,\n",
      "       0.0661599 , 0.49518202, 0.51278956, 0.13093346, 0.21179072,\n",
      "       0.05581336, 0.4170351 , 0.09209166, 0.1971513 , 0.00969117,\n",
      "       0.01773189, 0.06881894, 0.02773833, 0.0429088 , 0.07172406,\n",
      "       0.02460138, 0.03744038, 0.23821902]), 'mean_score_time': array([0.05419183, 0.07280596, 0.07180929, 0.07479986, 0.06948058,\n",
      "       0.07679534, 0.08444126, 0.0664897 , 0.07346964, 0.07380239,\n",
      "       0.07213982, 0.07014616, 0.07978868, 0.07347027, 0.02094412,\n",
      "       0.05119809, 0.01795149, 0.08078543, 0.05119705, 0.06748605,\n",
      "       0.07180675, 0.07080952, 0.07712825, 0.07845704, 0.08809892,\n",
      "       0.07646306, 0.0771277 , 0.08577061, 0.07983446, 0.03541692,\n",
      "       0.0620664 , 0.08809924, 0.08207464, 0.08640885, 0.07906723,\n",
      "       0.07901859, 0.07288845, 0.09941459, 0.09597357, 0.09615588,\n",
      "       0.05754606, 0.0783488 , 0.07843272, 0.08869561, 0.08871571,\n",
      "       0.07131743, 0.08676807, 0.09042549, 0.07679502, 0.07712762,\n",
      "       0.01795173, 0.07479954, 0.01761921, 0.08510494, 0.08410764,\n",
      "       0.0804526 , 0.08144951, 0.07180834, 0.07945498, 0.09873668,\n",
      "       0.07779241, 0.0867664 , 0.08029628, 0.05518619, 0.08147542,\n",
      "       0.0774157 , 0.07350032, 0.07390436, 0.07828712, 0.10446239,\n",
      "       0.06893349, 0.02082284, 0.07267467, 0.07472873, 0.08534153,\n",
      "       0.07567167, 0.08126601, 0.07247957, 0.07429624, 0.07457662,\n",
      "       0.07347329, 0.08058675, 0.08270621, 0.05919417, 0.07632264,\n",
      "       0.01708659, 0.06921347, 0.01905171, 0.08239214, 0.07903051,\n",
      "       0.07162015, 0.07027356, 0.07536666, 0.13846429, 0.07143005,\n",
      "       0.07194916, 0.08349705, 0.07283767, 0.08362667, 0.07570791,\n",
      "       0.08474906, 0.0706617 , 0.0785497 , 0.07204239, 0.06797425,\n",
      "       0.07428241, 0.07593854, 0.07745155, 0.07466841, 0.08862575,\n",
      "       0.07278792, 0.08252176, 0.07688236, 0.01796611, 0.07432254,\n",
      "       0.01813181, 0.07353942, 0.06703544, 0.07407371, 0.07669473,\n",
      "       0.0811375 , 0.07243069, 0.07436021, 0.07198874, 0.07836676,\n",
      "       0.05876406, 0.07943177, 0.01811584, 0.06030726, 0.0164272 ,\n",
      "       0.07662249, 0.08197482, 0.0688134 , 0.08181572, 0.06962895,\n",
      "       0.07423131, 0.07824858, 0.07661152, 0.06568797, 0.03860378,\n",
      "       0.08751456, 0.0540572 , 0.07204723, 0.0834674 , 0.07875848,\n",
      "       0.07808479, 0.07481742, 0.07718706, 0.06955552, 0.07817181,\n",
      "       0.03271286, 0.087322  , 0.07081644, 0.06915903, 0.08272219,\n",
      "       0.08231425, 0.0750401 , 0.08220514, 0.09081642, 0.07776101,\n",
      "       0.03334101, 0.058261  , 0.01831174, 0.07061148, 0.0908366 ,\n",
      "       0.08212376, 0.07042217, 0.07403859, 0.06570729, 0.07644018,\n",
      "       0.06922658, 0.07815862, 0.08660372, 0.08288225, 0.07568733,\n",
      "       0.07233914, 0.01901054, 0.07751497, 0.01694059, 0.06767162,\n",
      "       0.01909598, 0.07596286, 0.07389307, 0.06874466, 0.07554817,\n",
      "       0.08636411, 0.06852317, 0.08143441, 0.07529887, 0.07269748,\n",
      "       0.0689714 , 0.07472102, 0.07917094, 0.03755418, 0.07067323,\n",
      "       0.03478098, 0.08994246, 0.06859605, 0.07879027, 0.07874521,\n",
      "       0.09931986, 0.06961799, 0.07188352, 0.0672845 , 0.07537111,\n",
      "       0.04073509, 0.03529294, 0.01755699, 0.08332729, 0.07985091,\n",
      "       0.06710219, 0.08591032, 0.07435973, 0.07513817, 0.07428002,\n",
      "       0.07214538, 0.0787216 , 0.08559505, 0.07474343, 0.07384825,\n",
      "       0.0693388 , 0.08069762, 0.07404081, 0.08610264, 0.06767853,\n",
      "       0.07553593, 0.14239128, 0.07483021, 0.16603192, 0.01983754,\n",
      "       0.08206574, 0.01814334, 0.08100605, 0.07422606, 0.07568494,\n",
      "       0.08189209, 0.08161259, 0.07704798, 0.07153686, 0.07618809,\n",
      "       0.07843065, 0.0696756 , 0.01916877]), 'std_score_time': array([1.95136951e-02, 2.15276938e-03, 2.15457265e-03, 1.41113271e-03,\n",
      "       4.48495207e-03, 5.87167563e-03, 1.05957348e-02, 4.63069997e-03,\n",
      "       5.42314168e-03, 8.14880182e-04, 2.48803417e-03, 3.08313227e-03,\n",
      "       3.25883893e-03, 3.84881033e-03, 4.30903365e-03, 2.28358455e-02,\n",
      "       3.89335909e-07, 3.25776825e-03, 2.42162898e-02, 3.84743723e-03,\n",
      "       1.36730278e-06, 5.64458700e-03, 1.33888794e-02, 1.40185434e-02,\n",
      "       1.59242068e-02, 1.37318375e-02, 7.56669203e-03, 9.06929537e-03,\n",
      "       3.61943875e-02, 1.49626509e-02, 3.39615210e-02, 1.69543172e-02,\n",
      "       4.62487494e-03, 1.49906683e-02, 4.30106569e-03, 5.70708633e-03,\n",
      "       4.70804942e-03, 5.28827913e-03, 1.47806831e-02, 3.38522521e-03,\n",
      "       2.92222623e-02, 5.37786327e-03, 4.85610739e-03, 6.52133007e-03,\n",
      "       4.05075901e-03, 5.68396306e-03, 1.43131269e-02, 1.44825713e-02,\n",
      "       4.53312677e-03, 3.08281524e-03, 8.13614734e-04, 5.33945883e-03,\n",
      "       4.69740686e-04, 1.76973933e-02, 1.03097402e-02, 7.29834544e-03,\n",
      "       9.43916291e-03, 8.14978247e-04, 7.56592040e-03, 1.27975184e-02,\n",
      "       5.87205335e-03, 8.61549219e-03, 3.18282363e-03, 5.40723367e-02,\n",
      "       2.32427999e-03, 2.48623019e-03, 5.19224619e-03, 4.45428506e-03,\n",
      "       6.46609360e-03, 2.52291388e-02, 3.39702112e-03, 3.87773954e-03,\n",
      "       2.37367283e-03, 4.83401948e-02, 1.86995964e-03, 1.00268349e-02,\n",
      "       1.64054942e-02, 6.39496947e-03, 7.90369991e-03, 7.40320620e-03,\n",
      "       2.31249784e-03, 5.30314268e-03, 2.67114152e-03, 2.53699371e-02,\n",
      "       1.99939216e-03, 1.10034128e-04, 3.81046475e-03, 3.24682947e-03,\n",
      "       1.02064760e-02, 4.86498821e-04, 1.13094325e-03, 2.59775936e-03,\n",
      "       4.99081830e-03, 5.53802555e-02, 1.81236331e-03, 3.90068368e-03,\n",
      "       1.33329721e-02, 5.79331594e-03, 3.74769010e-03, 6.70208404e-03,\n",
      "       1.01893760e-02, 8.60909887e-03, 6.05907779e-03, 5.35937807e-03,\n",
      "       6.41637076e-04, 4.43326992e-03, 7.13756517e-03, 8.12896285e-03,\n",
      "       9.34437106e-04, 2.57254497e-02, 7.05791376e-03, 4.83319260e-03,\n",
      "       6.15411928e-03, 4.35970188e-04, 5.83101882e-03, 4.09921919e-04,\n",
      "       7.54144208e-03, 1.63472666e-03, 4.11783858e-03, 7.35982673e-03,\n",
      "       1.90623024e-02, 3.33820070e-03, 5.06728953e-03, 5.06514480e-03,\n",
      "       2.84634062e-03, 2.43793256e-02, 6.29336716e-03, 9.19222584e-04,\n",
      "       3.06001873e-02, 2.21075641e-04, 4.94019033e-03, 9.51726712e-03,\n",
      "       5.75436520e-03, 1.45744382e-02, 4.03611672e-03, 8.54444423e-03,\n",
      "       7.21024812e-03, 6.16470383e-03, 2.40473258e-03, 2.59625596e-02,\n",
      "       4.19701580e-03, 2.67548295e-02, 4.53926786e-03, 1.13853745e-02,\n",
      "       6.94976495e-03, 2.69722615e-03, 2.41947064e-03, 4.67008102e-03,\n",
      "       1.93942047e-03, 2.29330473e-03, 2.20628827e-02, 2.27298022e-02,\n",
      "       2.93327864e-03, 3.79658510e-03, 9.77895778e-03, 7.30997328e-03,\n",
      "       3.91006311e-03, 1.28305231e-02, 1.33894167e-02, 9.99676972e-03,\n",
      "       2.14801748e-02, 2.86076853e-02, 1.01260816e-03, 2.86635304e-02,\n",
      "       1.86947919e-02, 1.25885016e-02, 5.65926523e-03, 7.19378072e-03,\n",
      "       4.38100585e-03, 7.66574632e-03, 2.64026619e-03, 1.06066668e-02,\n",
      "       8.28152054e-03, 2.32242013e-03, 1.31555401e-02, 9.43407350e-03,\n",
      "       1.00717085e-03, 1.30314065e-02, 8.16375945e-04, 4.28258254e-03,\n",
      "       1.97599458e-03, 5.55752676e-03, 3.45041538e-03, 6.77289261e-03,\n",
      "       8.82579915e-03, 6.41599234e-03, 1.29331539e-03, 1.66855574e-03,\n",
      "       9.45578148e-03, 7.53658813e-03, 7.27633541e-03, 3.67221626e-03,\n",
      "       1.05356742e-02, 2.62432305e-02, 4.25554893e-03, 2.42337381e-02,\n",
      "       1.33992519e-02, 1.14003306e-03, 8.78440895e-03, 1.44251850e-02,\n",
      "       2.48337894e-02, 1.03285324e-02, 7.12940820e-03, 2.30551333e-03,\n",
      "       4.19639249e-03, 2.62196956e-02, 2.55258246e-02, 1.57450667e-03,\n",
      "       8.89778321e-03, 1.11386306e-02, 5.24734554e-03, 5.19503363e-03,\n",
      "       7.86829868e-03, 7.80580327e-03, 1.00508533e-02, 2.97104697e-03,\n",
      "       1.56959746e-02, 1.10494891e-02, 4.43891441e-03, 5.63719121e-03,\n",
      "       4.86881098e-03, 1.11711343e-02, 6.98217989e-03, 9.45541327e-03,\n",
      "       2.94503663e-03, 5.93946014e-03, 2.34190845e-02, 5.99505791e-03,\n",
      "       6.63308152e-02, 1.33830933e-03, 1.06940645e-02, 1.10238887e-03,\n",
      "       1.25955355e-02, 4.03651947e-03, 7.10081852e-03, 5.66316382e-03,\n",
      "       7.41875946e-03, 9.14220234e-03, 2.46935757e-03, 5.47340505e-03,\n",
      "       1.56847657e-03, 3.15312340e-03, 2.81708582e-03]), 'param_model__learning_rate': masked_array(data=[0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
      "                   0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
      "                   0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
      "                   0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
      "                   0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
      "                   0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
      "                   0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
      "                   0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
      "                   0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False],\n",
      "       fill_value=1e+20), 'param_model__max_depth': masked_array(data=[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "                   3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "                   7, 7, 7, 7, 7, 7, 7, 7, 7, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "                   3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "                   7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "                   3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "                   3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "                   7, 7, 7, 7, 7, 7, 7, 7, 7],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False],\n",
      "       fill_value=999999), 'param_model__min_samples_leaf': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False],\n",
      "       fill_value=999999), 'param_model__min_samples_split': masked_array(data=[2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10,\n",
      "                   10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10,\n",
      "                   10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5,\n",
      "                   10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5,\n",
      "                   5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2,\n",
      "                   2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10,\n",
      "                   2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10,\n",
      "                   10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10,\n",
      "                   10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5,\n",
      "                   10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5,\n",
      "                   5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2,\n",
      "                   2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10,\n",
      "                   2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10,\n",
      "                   10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10,\n",
      "                   10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False],\n",
      "       fill_value=999999), 'param_model__n_estimators': masked_array(data=[100, 200, 300, 100, 200, 300, 100, 200, 300, 100, 200,\n",
      "                   300, 100, 200, 300, 100, 200, 300, 100, 200, 300, 100,\n",
      "                   200, 300, 100, 200, 300, 100, 200, 300, 100, 200, 300,\n",
      "                   100, 200, 300, 100, 200, 300, 100, 200, 300, 100, 200,\n",
      "                   300, 100, 200, 300, 100, 200, 300, 100, 200, 300, 100,\n",
      "                   200, 300, 100, 200, 300, 100, 200, 300, 100, 200, 300,\n",
      "                   100, 200, 300, 100, 200, 300, 100, 200, 300, 100, 200,\n",
      "                   300, 100, 200, 300, 100, 200, 300, 100, 200, 300, 100,\n",
      "                   200, 300, 100, 200, 300, 100, 200, 300, 100, 200, 300,\n",
      "                   100, 200, 300, 100, 200, 300, 100, 200, 300, 100, 200,\n",
      "                   300, 100, 200, 300, 100, 200, 300, 100, 200, 300, 100,\n",
      "                   200, 300, 100, 200, 300, 100, 200, 300, 100, 200, 300,\n",
      "                   100, 200, 300, 100, 200, 300, 100, 200, 300, 100, 200,\n",
      "                   300, 100, 200, 300, 100, 200, 300, 100, 200, 300, 100,\n",
      "                   200, 300, 100, 200, 300, 100, 200, 300, 100, 200, 300,\n",
      "                   100, 200, 300, 100, 200, 300, 100, 200, 300, 100, 200,\n",
      "                   300, 100, 200, 300, 100, 200, 300, 100, 200, 300, 100,\n",
      "                   200, 300, 100, 200, 300, 100, 200, 300, 100, 200, 300,\n",
      "                   100, 200, 300, 100, 200, 300, 100, 200, 300, 100, 200,\n",
      "                   300, 100, 200, 300, 100, 200, 300, 100, 200, 300, 100,\n",
      "                   200, 300, 100, 200, 300, 100, 200, 300, 100, 200, 300,\n",
      "                   100, 200, 300, 100, 200, 300, 100, 200, 300, 100, 200,\n",
      "                   300],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False],\n",
      "       fill_value=999999), 'params': [{'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 100}, {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}, {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 300}, {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 100}, {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 200}, {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 300}, {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 100}, {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 200}, {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 300}, {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 100}, {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 200}, {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 300}, {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 100}, {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 200}, {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 300}, {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10, 'model__n_estimators': 100}, {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10, 'model__n_estimators': 200}, {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10, 'model__n_estimators': 300}, {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__n_estimators': 100}, {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__n_estimators': 200}, {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__n_estimators': 300}, {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 100}, {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 200}, {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 300}, {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__min_samples_leaf': 4, 'model__min_samples_split': 10, 'model__n_estimators': 100}, {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__min_samples_leaf': 4, 'model__min_samples_split': 10, 'model__n_estimators': 200}, {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__min_samples_leaf': 4, 'model__min_samples_split': 10, 'model__n_estimators': 300}, {'model__learning_rate': 0.01, 'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 100}, {'model__learning_rate': 0.01, 'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}, {'model__learning_rate': 0.01, 'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 300}, {'model__learning_rate': 0.01, 'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 100}, {'model__learning_rate': 0.01, 'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 200}, {'model__learning_rate': 0.01, 'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 300}, {'model__learning_rate': 0.01, 'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 100}, {'model__learning_rate': 0.01, 'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 200}, {'model__learning_rate': 0.01, 'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 300}, {'model__learning_rate': 0.01, 'model__max_depth': 5, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 100}, {'model__learning_rate': 0.01, 'model__max_depth': 5, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 200}, {'model__learning_rate': 0.01, 'model__max_depth': 5, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 300}, {'model__learning_rate': 0.01, 'model__max_depth': 5, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 100}, {'model__learning_rate': 0.01, 'model__max_depth': 5, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 200}, {'model__learning_rate': 0.01, 'model__max_depth': 5, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 300}, {'model__learning_rate': 0.01, 'model__max_depth': 5, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10, 'model__n_estimators': 100}, {'model__learning_rate': 0.01, 'model__max_depth': 5, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10, 'model__n_estimators': 200}, {'model__learning_rate': 0.01, 'model__max_depth': 5, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10, 'model__n_estimators': 300}, {'model__learning_rate': 0.01, 'model__max_depth': 5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__n_estimators': 100}, {'model__learning_rate': 0.01, 'model__max_depth': 5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__n_estimators': 200}, {'model__learning_rate': 0.01, 'model__max_depth': 5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__n_estimators': 300}, {'model__learning_rate': 0.01, 'model__max_depth': 5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 100}, {'model__learning_rate': 0.01, 'model__max_depth': 5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 200}, {'model__learning_rate': 0.01, 'model__max_depth': 5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 300}, {'model__learning_rate': 0.01, 'model__max_depth': 5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 10, 'model__n_estimators': 100}, {'model__learning_rate': 0.01, 'model__max_depth': 5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 10, 'model__n_estimators': 200}, {'model__learning_rate': 0.01, 'model__max_depth': 5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 10, 'model__n_estimators': 300}, {'model__learning_rate': 0.01, 'model__max_depth': 7, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 100}, {'model__learning_rate': 0.01, 'model__max_depth': 7, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}, {'model__learning_rate': 0.01, 'model__max_depth': 7, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 300}, {'model__learning_rate': 0.01, 'model__max_depth': 7, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 100}, {'model__learning_rate': 0.01, 'model__max_depth': 7, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 200}, {'model__learning_rate': 0.01, 'model__max_depth': 7, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 300}, {'model__learning_rate': 0.01, 'model__max_depth': 7, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 100}, {'model__learning_rate': 0.01, 'model__max_depth': 7, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 200}, {'model__learning_rate': 0.01, 'model__max_depth': 7, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 300}, {'model__learning_rate': 0.01, 'model__max_depth': 7, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 100}, {'model__learning_rate': 0.01, 'model__max_depth': 7, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 200}, {'model__learning_rate': 0.01, 'model__max_depth': 7, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 300}, {'model__learning_rate': 0.01, 'model__max_depth': 7, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 100}, {'model__learning_rate': 0.01, 'model__max_depth': 7, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 200}, {'model__learning_rate': 0.01, 'model__max_depth': 7, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 300}, {'model__learning_rate': 0.01, 'model__max_depth': 7, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10, 'model__n_estimators': 100}, {'model__learning_rate': 0.01, 'model__max_depth': 7, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10, 'model__n_estimators': 200}, {'model__learning_rate': 0.01, 'model__max_depth': 7, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10, 'model__n_estimators': 300}, {'model__learning_rate': 0.01, 'model__max_depth': 7, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__n_estimators': 100}, {'model__learning_rate': 0.01, 'model__max_depth': 7, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__n_estimators': 200}, {'model__learning_rate': 0.01, 'model__max_depth': 7, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__n_estimators': 300}, {'model__learning_rate': 0.01, 'model__max_depth': 7, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 100}, {'model__learning_rate': 0.01, 'model__max_depth': 7, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 200}, {'model__learning_rate': 0.01, 'model__max_depth': 7, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 300}, {'model__learning_rate': 0.01, 'model__max_depth': 7, 'model__min_samples_leaf': 4, 'model__min_samples_split': 10, 'model__n_estimators': 100}, {'model__learning_rate': 0.01, 'model__max_depth': 7, 'model__min_samples_leaf': 4, 'model__min_samples_split': 10, 'model__n_estimators': 200}, {'model__learning_rate': 0.01, 'model__max_depth': 7, 'model__min_samples_leaf': 4, 'model__min_samples_split': 10, 'model__n_estimators': 300}, {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 100}, {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}, {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 300}, {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 100}, {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 200}, {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 300}, {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 100}, {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 200}, {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 300}, {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 100}, {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 200}, {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 300}, {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 100}, {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 200}, {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 300}, {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10, 'model__n_estimators': 100}, {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10, 'model__n_estimators': 200}, {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10, 'model__n_estimators': 300}, {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__n_estimators': 100}, {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__n_estimators': 200}, {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__n_estimators': 300}, {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 100}, {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 200}, {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 300}, {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__min_samples_leaf': 4, 'model__min_samples_split': 10, 'model__n_estimators': 100}, {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__min_samples_leaf': 4, 'model__min_samples_split': 10, 'model__n_estimators': 200}, {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__min_samples_leaf': 4, 'model__min_samples_split': 10, 'model__n_estimators': 300}, {'model__learning_rate': 0.05, 'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 100}, {'model__learning_rate': 0.05, 'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}, {'model__learning_rate': 0.05, 'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 300}, {'model__learning_rate': 0.05, 'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 100}, {'model__learning_rate': 0.05, 'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 200}, {'model__learning_rate': 0.05, 'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 300}, {'model__learning_rate': 0.05, 'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 100}, {'model__learning_rate': 0.05, 'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 200}, {'model__learning_rate': 0.05, 'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 300}, {'model__learning_rate': 0.05, 'model__max_depth': 5, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 100}, {'model__learning_rate': 0.05, 'model__max_depth': 5, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 200}, {'model__learning_rate': 0.05, 'model__max_depth': 5, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 300}, {'model__learning_rate': 0.05, 'model__max_depth': 5, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 100}, {'model__learning_rate': 0.05, 'model__max_depth': 5, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 200}, {'model__learning_rate': 0.05, 'model__max_depth': 5, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 300}, {'model__learning_rate': 0.05, 'model__max_depth': 5, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10, 'model__n_estimators': 100}, {'model__learning_rate': 0.05, 'model__max_depth': 5, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10, 'model__n_estimators': 200}, {'model__learning_rate': 0.05, 'model__max_depth': 5, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10, 'model__n_estimators': 300}, {'model__learning_rate': 0.05, 'model__max_depth': 5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__n_estimators': 100}, {'model__learning_rate': 0.05, 'model__max_depth': 5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__n_estimators': 200}, {'model__learning_rate': 0.05, 'model__max_depth': 5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__n_estimators': 300}, {'model__learning_rate': 0.05, 'model__max_depth': 5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 100}, {'model__learning_rate': 0.05, 'model__max_depth': 5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 200}, {'model__learning_rate': 0.05, 'model__max_depth': 5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 300}, {'model__learning_rate': 0.05, 'model__max_depth': 5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 10, 'model__n_estimators': 100}, {'model__learning_rate': 0.05, 'model__max_depth': 5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 10, 'model__n_estimators': 200}, {'model__learning_rate': 0.05, 'model__max_depth': 5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 10, 'model__n_estimators': 300}, {'model__learning_rate': 0.05, 'model__max_depth': 7, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 100}, {'model__learning_rate': 0.05, 'model__max_depth': 7, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}, {'model__learning_rate': 0.05, 'model__max_depth': 7, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 300}, {'model__learning_rate': 0.05, 'model__max_depth': 7, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 100}, {'model__learning_rate': 0.05, 'model__max_depth': 7, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 200}, {'model__learning_rate': 0.05, 'model__max_depth': 7, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 300}, {'model__learning_rate': 0.05, 'model__max_depth': 7, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 100}, {'model__learning_rate': 0.05, 'model__max_depth': 7, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 200}, {'model__learning_rate': 0.05, 'model__max_depth': 7, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 300}, {'model__learning_rate': 0.05, 'model__max_depth': 7, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 100}, {'model__learning_rate': 0.05, 'model__max_depth': 7, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 200}, {'model__learning_rate': 0.05, 'model__max_depth': 7, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 300}, {'model__learning_rate': 0.05, 'model__max_depth': 7, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 100}, {'model__learning_rate': 0.05, 'model__max_depth': 7, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 200}, {'model__learning_rate': 0.05, 'model__max_depth': 7, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 300}, {'model__learning_rate': 0.05, 'model__max_depth': 7, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10, 'model__n_estimators': 100}, {'model__learning_rate': 0.05, 'model__max_depth': 7, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10, 'model__n_estimators': 200}, {'model__learning_rate': 0.05, 'model__max_depth': 7, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10, 'model__n_estimators': 300}, {'model__learning_rate': 0.05, 'model__max_depth': 7, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__n_estimators': 100}, {'model__learning_rate': 0.05, 'model__max_depth': 7, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__n_estimators': 200}, {'model__learning_rate': 0.05, 'model__max_depth': 7, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__n_estimators': 300}, {'model__learning_rate': 0.05, 'model__max_depth': 7, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 100}, {'model__learning_rate': 0.05, 'model__max_depth': 7, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 200}, {'model__learning_rate': 0.05, 'model__max_depth': 7, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 300}, {'model__learning_rate': 0.05, 'model__max_depth': 7, 'model__min_samples_leaf': 4, 'model__min_samples_split': 10, 'model__n_estimators': 100}, {'model__learning_rate': 0.05, 'model__max_depth': 7, 'model__min_samples_leaf': 4, 'model__min_samples_split': 10, 'model__n_estimators': 200}, {'model__learning_rate': 0.05, 'model__max_depth': 7, 'model__min_samples_leaf': 4, 'model__min_samples_split': 10, 'model__n_estimators': 300}, {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 100}, {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}, {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 300}, {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 100}, {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 200}, {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 300}, {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 100}, {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 200}, {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 300}, {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 100}, {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 200}, {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 300}, {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 100}, {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 200}, {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 300}, {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10, 'model__n_estimators': 100}, {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10, 'model__n_estimators': 200}, {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10, 'model__n_estimators': 300}, {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__n_estimators': 100}, {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__n_estimators': 200}, {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__n_estimators': 300}, {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 100}, {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 200}, {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 300}, {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_leaf': 4, 'model__min_samples_split': 10, 'model__n_estimators': 100}, {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_leaf': 4, 'model__min_samples_split': 10, 'model__n_estimators': 200}, {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_leaf': 4, 'model__min_samples_split': 10, 'model__n_estimators': 300}, {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 100}, {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}, {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 300}, {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 100}, {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 200}, {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 300}, {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 100}, {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 200}, {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 300}, {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 100}, {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 200}, {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 300}, {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 100}, {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 200}, {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 300}, {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10, 'model__n_estimators': 100}, {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10, 'model__n_estimators': 200}, {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10, 'model__n_estimators': 300}, {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__n_estimators': 100}, {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__n_estimators': 200}, {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__n_estimators': 300}, {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 100}, {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 200}, {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 300}, {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 10, 'model__n_estimators': 100}, {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 10, 'model__n_estimators': 200}, {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__min_samples_leaf': 4, 'model__min_samples_split': 10, 'model__n_estimators': 300}, {'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 100}, {'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}, {'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 300}, {'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 100}, {'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 200}, {'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5, 'model__n_estimators': 300}, {'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 100}, {'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 200}, {'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 300}, {'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 100}, {'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 200}, {'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__n_estimators': 300}, {'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 100}, {'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 200}, {'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 300}, {'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10, 'model__n_estimators': 100}, {'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10, 'model__n_estimators': 200}, {'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10, 'model__n_estimators': 300}, {'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__n_estimators': 100}, {'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__n_estimators': 200}, {'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__n_estimators': 300}, {'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 100}, {'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 200}, {'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_samples_leaf': 4, 'model__min_samples_split': 5, 'model__n_estimators': 300}, {'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_samples_leaf': 4, 'model__min_samples_split': 10, 'model__n_estimators': 100}, {'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_samples_leaf': 4, 'model__min_samples_split': 10, 'model__n_estimators': 200}, {'model__learning_rate': 0.1, 'model__max_depth': 7, 'model__min_samples_leaf': 4, 'model__min_samples_split': 10, 'model__n_estimators': 300}], 'split0_test_score': array([-0.0360676 , -0.00666331, -0.00209545, -0.0360676 , -0.00666331,\n",
      "       -0.00209545, -0.0360676 , -0.00677575, -0.00196188, -0.03460381,\n",
      "       -0.00737052, -0.00315299, -0.03460381, -0.007513  , -0.00353905,\n",
      "       -0.03460381, -0.00747722, -0.00349595, -0.03568203, -0.00768644,\n",
      "       -0.003667  , -0.03568203, -0.00768644, -0.003667  , -0.03568203,\n",
      "       -0.00768644, -0.003667  , -0.03675884, -0.00837473, -0.00403368,\n",
      "       -0.03430448, -0.00733414, -0.00357979, -0.03405502, -0.00699906,\n",
      "       -0.0033295 , -0.03435196, -0.00742242, -0.00349033, -0.03309327,\n",
      "       -0.00697802, -0.00338393, -0.0331075 , -0.00674776, -0.00320997,\n",
      "       -0.03450653, -0.00744019, -0.00397605, -0.03450653, -0.00744019,\n",
      "       -0.00397605, -0.0344111 , -0.00740807, -0.00400514, -0.03654643,\n",
      "       -0.00819299, -0.00397545, -0.03406733, -0.00736999, -0.00411824,\n",
      "       -0.03405032, -0.00704645, -0.00374008, -0.03424735, -0.00732919,\n",
      "       -0.00352706, -0.03310576, -0.00695123, -0.00338242, -0.033129  ,\n",
      "       -0.00676521, -0.00326241, -0.03455217, -0.00749026, -0.00397345,\n",
      "       -0.03455217, -0.00749026, -0.00397345, -0.03438717, -0.00747852,\n",
      "       -0.00403653, -0.0014285 , -0.00136154, -0.00136095, -0.00144254,\n",
      "       -0.00137412, -0.00137335, -0.00111513, -0.00101757, -0.00101664,\n",
      "       -0.00257959, -0.00281209, -0.00282067, -0.00294592, -0.00336495,\n",
      "       -0.00339689, -0.00287792, -0.00317406, -0.00344298, -0.00322534,\n",
      "       -0.00367398, -0.00404346, -0.00322534, -0.00367398, -0.00404346,\n",
      "       -0.0031569 , -0.00339327, -0.00363128, -0.00290553, -0.00285052,\n",
      "       -0.00285023, -0.00211739, -0.00209971, -0.00209966, -0.00150313,\n",
      "       -0.00151288, -0.0015129 , -0.00300654, -0.00334225, -0.00344302,\n",
      "       -0.00294466, -0.00341938, -0.00358196, -0.00273839, -0.00286845,\n",
      "       -0.00302429, -0.00376503, -0.00426863, -0.00453217, -0.00376503,\n",
      "       -0.00426863, -0.00453217, -0.00376738, -0.00409587, -0.00428675,\n",
      "       -0.00292445, -0.00287346, -0.0028732 , -0.00278308, -0.00281456,\n",
      "       -0.00281475, -0.00206126, -0.00208897, -0.00208919, -0.00322803,\n",
      "       -0.00363836, -0.0037589 , -0.00294598, -0.00338579, -0.00353541,\n",
      "       -0.00273902, -0.00287791, -0.00299737, -0.00381216, -0.00433777,\n",
      "       -0.00457005, -0.00381216, -0.00433777, -0.00457005, -0.00386266,\n",
      "       -0.00428028, -0.00450088, -0.00070015, -0.00069964, -0.00069964,\n",
      "       -0.00071832, -0.00071739, -0.0007173 , -0.00059663, -0.00059579,\n",
      "       -0.00059568, -0.00274623, -0.00276468, -0.00277424, -0.00340298,\n",
      "       -0.00344481, -0.00345177, -0.00355265, -0.00360509, -0.00360907,\n",
      "       -0.00385735, -0.00422344, -0.00427988, -0.00385735, -0.00422344,\n",
      "       -0.00427988, -0.00350162, -0.00407194, -0.00412092, -0.00316116,\n",
      "       -0.00316095, -0.00316095, -0.00147619, -0.00147612, -0.00147612,\n",
      "       -0.00141741, -0.00141741, -0.00141741, -0.00351012, -0.00362532,\n",
      "       -0.00362528, -0.00347333, -0.00358132, -0.00358259, -0.00291505,\n",
      "       -0.00312204, -0.00323874, -0.00432584, -0.0047281 , -0.0048721 ,\n",
      "       -0.00432584, -0.0047281 , -0.0048721 , -0.0040678 , -0.00442305,\n",
      "       -0.00458774, -0.00318787, -0.00318764, -0.00318764, -0.00209293,\n",
      "       -0.00209314, -0.00209314, -0.00139775, -0.00139791, -0.00139791,\n",
      "       -0.00345377, -0.00356951, -0.00357334, -0.00342033, -0.00358679,\n",
      "       -0.0035919 , -0.00294847, -0.00316737, -0.0032838 , -0.00431614,\n",
      "       -0.00464369, -0.00475541, -0.00431614, -0.00464369, -0.00475541,\n",
      "       -0.00409223, -0.00446598, -0.00465452]), 'split1_test_score': array([-0.02903308, -0.00468011, -0.00131927, -0.02903308, -0.00468011,\n",
      "       -0.00131927, -0.02903308, -0.00450917, -0.00086406, -0.03196123,\n",
      "       -0.00779566, -0.00434126, -0.03196123, -0.00779566, -0.00434126,\n",
      "       -0.03196123, -0.00764127, -0.003944  , -0.0311576 , -0.00719905,\n",
      "       -0.00379611, -0.0311576 , -0.00719905, -0.00379611, -0.0311576 ,\n",
      "       -0.00719905, -0.00378011, -0.03074984, -0.00735771, -0.0041503 ,\n",
      "       -0.03064781, -0.00718165, -0.00399101, -0.02783117, -0.00383846,\n",
      "       -0.00068808, -0.03133496, -0.00792481, -0.00465825, -0.03145186,\n",
      "       -0.00800168, -0.0047096 , -0.03122607, -0.00743495, -0.0041713 ,\n",
      "       -0.03059986, -0.00696347, -0.00369504, -0.03059986, -0.00696347,\n",
      "       -0.00369504, -0.03056   , -0.00688599, -0.00365311, -0.03077565,\n",
      "       -0.00748982, -0.00429798, -0.03037474, -0.0072707 , -0.00419526,\n",
      "       -0.02769874, -0.00375429, -0.00066345, -0.03110313, -0.00790979,\n",
      "       -0.00463666, -0.03122759, -0.00799062, -0.00474377, -0.03119398,\n",
      "       -0.00740935, -0.00420385, -0.03050645, -0.00692929, -0.00367655,\n",
      "       -0.03050645, -0.00692929, -0.00367655, -0.03049768, -0.00685111,\n",
      "       -0.00363231, -0.00080552, -0.00081116, -0.0008114 , -0.00080552,\n",
      "       -0.00081121, -0.00081138, -0.00023149, -0.00023019, -0.00023013,\n",
      "       -0.00410886, -0.00425275, -0.0042842 , -0.00410439, -0.00422066,\n",
      "       -0.00425149, -0.0031524 , -0.00306194, -0.00317277, -0.00315771,\n",
      "       -0.00307437, -0.00307377, -0.00315771, -0.00307437, -0.00307377,\n",
      "       -0.00305979, -0.00296168, -0.0029598 , -0.00365612, -0.00364018,\n",
      "       -0.00364013, -0.00374255, -0.00373291, -0.00373288, -0.00023801,\n",
      "       -0.00023681, -0.00023684, -0.0041967 , -0.00418566, -0.0041852 ,\n",
      "       -0.0041714 , -0.00412701, -0.00413487, -0.00332097, -0.00321061,\n",
      "       -0.00323479, -0.0030404 , -0.00301364, -0.00300388, -0.0030404 ,\n",
      "       -0.00301364, -0.00300388, -0.00296898, -0.00295157, -0.00296329,\n",
      "       -0.00381932, -0.00380821, -0.00380817, -0.00382338, -0.00382084,\n",
      "       -0.00382084, -0.00024898, -0.00025218, -0.00025224, -0.00396892,\n",
      "       -0.0038979 , -0.00388975, -0.00413397, -0.00405383, -0.00404739,\n",
      "       -0.00338155, -0.00330171, -0.00331631, -0.003041  , -0.00306234,\n",
      "       -0.00308527, -0.003041  , -0.00306234, -0.00308527, -0.00299695,\n",
      "       -0.00301798, -0.00302682, -0.00059705, -0.00059666, -0.00059669,\n",
      "       -0.00059675, -0.00059655, -0.00059657, -0.00023137, -0.00023154,\n",
      "       -0.00023148, -0.00424512, -0.00428218, -0.00428408, -0.00423388,\n",
      "       -0.00427632, -0.00427794, -0.00310484, -0.00320004, -0.00320396,\n",
      "       -0.00309151, -0.00311531, -0.003191  , -0.00309151, -0.00311531,\n",
      "       -0.003191  , -0.00304269, -0.00307427, -0.00314825, -0.00380471,\n",
      "       -0.00380468, -0.00380468, -0.00375757, -0.00375759, -0.00375759,\n",
      "       -0.00024147, -0.0002415 , -0.0002415 , -0.00378272, -0.00379135,\n",
      "       -0.00379213, -0.00408126, -0.00408861, -0.00408954, -0.00335803,\n",
      "       -0.00339455, -0.00339742, -0.0030309 , -0.00304952, -0.00310851,\n",
      "       -0.0030309 , -0.00304952, -0.00310851, -0.00298426, -0.00302904,\n",
      "       -0.00308814, -0.00395722, -0.00395722, -0.00395722, -0.00409685,\n",
      "       -0.0040969 , -0.0040969 , -0.00024536, -0.00024541, -0.00024541,\n",
      "       -0.00369033, -0.00368877, -0.00368949, -0.00396729, -0.00395762,\n",
      "       -0.00395737, -0.00319174, -0.00321577, -0.00321658, -0.00305131,\n",
      "       -0.00312985, -0.00321601, -0.00305131, -0.00312985, -0.00321601,\n",
      "       -0.00304131, -0.00309478, -0.00319938]), 'split2_test_score': array([-0.0335395 , -0.00539756, -0.00106865, -0.0335395 , -0.00539756,\n",
      "       -0.00106865, -0.03335093, -0.00527331, -0.00105271, -0.0335395 ,\n",
      "       -0.00539756, -0.00110497, -0.0335395 , -0.00539756, -0.00110497,\n",
      "       -0.03335093, -0.00527331, -0.00108502, -0.03157396, -0.00498847,\n",
      "       -0.0015556 , -0.03157396, -0.00498847, -0.0015556 , -0.03157396,\n",
      "       -0.00498847, -0.0015556 , -0.03263551, -0.00530822, -0.00125385,\n",
      "       -0.03232833, -0.00508541, -0.00110794, -0.03169307, -0.00474391,\n",
      "       -0.00093866, -0.03227852, -0.00536311, -0.00134072, -0.03220723,\n",
      "       -0.00524234, -0.00126288, -0.03162417, -0.00475716, -0.00096659,\n",
      "       -0.02944011, -0.00437155, -0.00143537, -0.02944011, -0.00437155,\n",
      "       -0.00143537, -0.02984785, -0.00448979, -0.00148587, -0.03276243,\n",
      "       -0.00554358, -0.00141257, -0.03218303, -0.00498687, -0.00109945,\n",
      "       -0.03168185, -0.00464234, -0.00087342, -0.03232838, -0.00548678,\n",
      "       -0.00142804, -0.03217103, -0.00520417, -0.00125666, -0.03159857,\n",
      "       -0.00473196, -0.00093497, -0.02931298, -0.00424497, -0.00142416,\n",
      "       -0.02931298, -0.00424497, -0.00142416, -0.02993827, -0.00443854,\n",
      "       -0.00146869, -0.00022726, -0.00018693, -0.0001867 , -0.00022726,\n",
      "       -0.00018686, -0.0001866 , -0.00022033, -0.0001715 , -0.00017118,\n",
      "       -0.00025392, -0.0002082 , -0.00020735, -0.00025392, -0.00020841,\n",
      "       -0.00020717, -0.00025827, -0.00020716, -0.00020449, -0.00133094,\n",
      "       -0.00171646, -0.00185814, -0.00133094, -0.00171646, -0.00185814,\n",
      "       -0.0013668 , -0.00161839, -0.00170248, -0.0003812 , -0.00033182,\n",
      "       -0.00033157, -0.00031154, -0.00026851, -0.00026827, -0.00024664,\n",
      "       -0.00022075, -0.00022063, -0.00051181, -0.00044222, -0.00043936,\n",
      "       -0.0004144 , -0.00035418, -0.00035299, -0.00027516, -0.00023486,\n",
      "       -0.00023176, -0.0013811 , -0.00197685, -0.00220529, -0.0013811 ,\n",
      "       -0.00197685, -0.00220529, -0.00138554, -0.00201688, -0.00226522,\n",
      "       -0.00053802, -0.00048092, -0.00048063, -0.00045505, -0.00042418,\n",
      "       -0.00042405, -0.00024898, -0.00023435, -0.00023432, -0.0006389 ,\n",
      "       -0.00057461, -0.00057654, -0.00043513, -0.00039192, -0.0003949 ,\n",
      "       -0.00023933, -0.0002079 , -0.00020443, -0.00157573, -0.00210341,\n",
      "       -0.00236035, -0.00157573, -0.00210341, -0.00236035, -0.00147106,\n",
      "       -0.00197336, -0.00225626, -0.0001804 , -0.00017966, -0.00017975,\n",
      "       -0.00018088, -0.00018054, -0.00018056, -0.00018396, -0.00018336,\n",
      "       -0.00018342, -0.00020499, -0.00020332, -0.00020339, -0.00021495,\n",
      "       -0.00021166, -0.00021181, -0.00018754, -0.00018439, -0.00018427,\n",
      "       -0.00168667, -0.00174958, -0.001755  , -0.00168667, -0.00174958,\n",
      "       -0.001755  , -0.00162424, -0.00174278, -0.00172553, -0.00037299,\n",
      "       -0.00037276, -0.00037276, -0.00029653, -0.00029636, -0.00029636,\n",
      "       -0.00021808, -0.00021801, -0.00021801, -0.00045576, -0.00045518,\n",
      "       -0.00045518, -0.00032889, -0.00032699, -0.00032703, -0.00023926,\n",
      "       -0.0002371 , -0.00023678, -0.00200505, -0.00225014, -0.00226945,\n",
      "       -0.00200505, -0.00225014, -0.00226945, -0.00189478, -0.00220605,\n",
      "       -0.00224632, -0.00050092, -0.00050069, -0.00050069, -0.00041824,\n",
      "       -0.00041814, -0.00041814, -0.00019557, -0.0001955 , -0.0001955 ,\n",
      "       -0.00059336, -0.00059499, -0.000595  , -0.00039299, -0.00039676,\n",
      "       -0.00039682, -0.00021002, -0.00020581, -0.0002058 , -0.00212876,\n",
      "       -0.00244978, -0.00251473, -0.00212876, -0.00244978, -0.00251473,\n",
      "       -0.00204468, -0.00255173, -0.00265042]), 'mean_test_score': array([-0.03288006, -0.00558032, -0.00149446, -0.03288006, -0.00558032,\n",
      "       -0.00149446, -0.0328172 , -0.00551941, -0.00129288, -0.03336818,\n",
      "       -0.00685458, -0.00286641, -0.03336818, -0.00690207, -0.00299509,\n",
      "       -0.03330532, -0.00679727, -0.00284166, -0.03280453, -0.00662466,\n",
      "       -0.00300624, -0.03280453, -0.00662466, -0.00300624, -0.03280453,\n",
      "       -0.00662466, -0.00300091, -0.0333814 , -0.00701355, -0.00314594,\n",
      "       -0.03242687, -0.00653373, -0.00289291, -0.03119309, -0.00519381,\n",
      "       -0.00165208, -0.03265515, -0.00690345, -0.0031631 , -0.03225079,\n",
      "       -0.00674068, -0.0031188 , -0.03198591, -0.00631329, -0.00278262,\n",
      "       -0.0315155 , -0.00625841, -0.00303549, -0.0315155 , -0.00625841,\n",
      "       -0.00303549, -0.03160631, -0.00626128, -0.00304804, -0.0333615 ,\n",
      "       -0.00707546, -0.00322866, -0.03220837, -0.00654252, -0.00313765,\n",
      "       -0.03114364, -0.00514769, -0.00175898, -0.03255962, -0.00690859,\n",
      "       -0.00319725, -0.03216812, -0.00671534, -0.00312762, -0.03197385,\n",
      "       -0.00630217, -0.00280041, -0.0314572 , -0.00622151, -0.00302472,\n",
      "       -0.0314572 , -0.00622151, -0.00302472, -0.03160771, -0.00625606,\n",
      "       -0.00304584, -0.00082043, -0.00078654, -0.00078635, -0.00082511,\n",
      "       -0.00079073, -0.00079045, -0.00052232, -0.00047309, -0.00047265,\n",
      "       -0.00231412, -0.00242435, -0.0024374 , -0.00243474, -0.00259801,\n",
      "       -0.00261852, -0.00209619, -0.00214772, -0.00227342, -0.00257133,\n",
      "       -0.0028216 , -0.00299179, -0.00257133, -0.0028216 , -0.00299179,\n",
      "       -0.00252783, -0.00265778, -0.00276452, -0.00231428, -0.00227417,\n",
      "       -0.00227398, -0.00205716, -0.00203371, -0.00203361, -0.00066259,\n",
      "       -0.00065681, -0.00065679, -0.00257168, -0.00265671, -0.00268919,\n",
      "       -0.00251015, -0.00263352, -0.00268994, -0.00211151, -0.00210464,\n",
      "       -0.00216361, -0.00272884, -0.00308637, -0.00324711, -0.00272884,\n",
      "       -0.00308637, -0.00324711, -0.0027073 , -0.00302144, -0.00317175,\n",
      "       -0.00242726, -0.00238753, -0.00238733, -0.00235384, -0.00235319,\n",
      "       -0.00235321, -0.00085307, -0.0008585 , -0.00085858, -0.00261195,\n",
      "       -0.00270363, -0.00274173, -0.00250503, -0.00261051, -0.00265924,\n",
      "       -0.00211997, -0.00212917, -0.0021727 , -0.00280963, -0.00316784,\n",
      "       -0.00333855, -0.00280963, -0.00316784, -0.00333855, -0.00277689,\n",
      "       -0.00309054, -0.00326132, -0.00049253, -0.00049199, -0.00049203,\n",
      "       -0.00049865, -0.00049816, -0.00049815, -0.00033732, -0.0003369 ,\n",
      "       -0.00033686, -0.00239878, -0.00241672, -0.00242057, -0.00261727,\n",
      "       -0.00264426, -0.00264717, -0.00228168, -0.00232984, -0.00233243,\n",
      "       -0.00287851, -0.00302944, -0.00307529, -0.00287851, -0.00302944,\n",
      "       -0.00307529, -0.00272285, -0.002963  , -0.00299823, -0.00244629,\n",
      "       -0.00244613, -0.00244613, -0.00184343, -0.00184336, -0.00184336,\n",
      "       -0.00062565, -0.00062564, -0.00062564, -0.00258287, -0.00262395,\n",
      "       -0.00262419, -0.00262783, -0.00266564, -0.00266639, -0.00217078,\n",
      "       -0.00225123, -0.00229098, -0.0031206 , -0.00334259, -0.00341669,\n",
      "       -0.0031206 , -0.00334259, -0.00341669, -0.00298228, -0.00321938,\n",
      "       -0.0033074 , -0.00254867, -0.00254852, -0.00254852, -0.00220267,\n",
      "       -0.00220273, -0.00220273, -0.00061289, -0.00061294, -0.00061294,\n",
      "       -0.00257915, -0.00261776, -0.00261928, -0.00259353, -0.00264706,\n",
      "       -0.0026487 , -0.00211674, -0.00219632, -0.00223539, -0.0031654 ,\n",
      "       -0.00340777, -0.00349539, -0.0031654 , -0.00340777, -0.00349539,\n",
      "       -0.00305941, -0.00337083, -0.00350144]), 'std_test_score': array([0.00290944, 0.00081989, 0.00043711, 0.00290944, 0.00081989,\n",
      "       0.00043711, 0.00289652, 0.00094155, 0.00047928, 0.00108561,\n",
      "       0.00104478, 0.00133666, 0.00108561, 0.00107009, 0.00137606,\n",
      "       0.00107931, 0.00107968, 0.00125553, 0.00204179, 0.00117394,\n",
      "       0.00102711, 0.00204179, 0.00117394, 0.00102711, 0.00204179,\n",
      "       0.00117394, 0.00102303, 0.00250922, 0.00127533, 0.00133876,\n",
      "       0.00149446, 0.00102601, 0.00127328, 0.00256535, 0.00132895,\n",
      "       0.00119052, 0.00126014, 0.00110833, 0.001374  , 0.00067081,\n",
      "       0.00113893, 0.00141955, 0.00080956, 0.00113555, 0.00134276,\n",
      "       0.00216732, 0.00134833, 0.00113725, 0.00216732, 0.00134833,\n",
      "       0.00113725, 0.00200448, 0.00127064, 0.00111393, 0.0023937 ,\n",
      "       0.0011206 , 0.00129091, 0.0015076 , 0.00110076, 0.00144157,\n",
      "       0.0026208 , 0.00139071, 0.00140347, 0.00129399, 0.00103294,\n",
      "       0.00133051, 0.00076676, 0.00114973, 0.00143496, 0.00083335,\n",
      "       0.00114103, 0.00137392, 0.00224206, 0.00141626, 0.00113824,\n",
      "       0.00224206, 0.00141626, 0.00113824, 0.0019786 , 0.00131046,\n",
      "       0.00112736, 0.00049052, 0.00047985, 0.00047971, 0.00049633,\n",
      "       0.00048491, 0.00048472, 0.00041921, 0.00038575, 0.00038541,\n",
      "       0.00158493, 0.00167379, 0.00168629, 0.00161297, 0.00172543,\n",
      "       0.00174041, 0.00130443, 0.00137295, 0.0014671 , 0.00087752,\n",
      "       0.0008189 , 0.00089403, 0.00087752, 0.0008189 , 0.00089403,\n",
      "       0.00082193, 0.00075578, 0.00079944, 0.00140082, 0.00141078,\n",
      "       0.00141084, 0.00140135, 0.0014151 , 0.00141519, 0.00059436,\n",
      "       0.00060537, 0.00060539, 0.00153545, 0.00160329, 0.00161947,\n",
      "       0.00156426, 0.00163743, 0.00166782, 0.00132009, 0.0013295 ,\n",
      "       0.00136872, 0.00099786, 0.00093703, 0.00096539, 0.00099786,\n",
      "       0.00093703, 0.00096539, 0.00098983, 0.00085018, 0.00083835,\n",
      "       0.00138495, 0.00140114, 0.00140123, 0.00140822, 0.00142454,\n",
      "       0.00142462, 0.00085432, 0.00087011, 0.0008702 , 0.00142757,\n",
      "       0.00150917, 0.00153195, 0.0015419 , 0.00159231, 0.00161471,\n",
      "       0.00135543, 0.00136951, 0.00139785, 0.00092756, 0.00091522,\n",
      "       0.00091971, 0.00092756, 0.00091522, 0.00091971, 0.00098869,\n",
      "       0.00094319, 0.00093124, 0.00022469, 0.00022482, 0.00022478,\n",
      "       0.00023011, 0.00022995, 0.00022991, 0.00018438, 0.00018412,\n",
      "       0.00018406, 0.00166758, 0.00168327, 0.0016846 , 0.00173223,\n",
      "       0.00175329, 0.00175478, 0.00149202, 0.00152605, 0.00152796,\n",
      "       0.00089888, 0.00101177, 0.00103402, 0.00089888, 0.00101177,\n",
      "       0.00103402, 0.00079911, 0.00095413, 0.00098365, 0.00148939,\n",
      "       0.00148946, 0.00148946, 0.00143663, 0.0014367 , 0.0014367 ,\n",
      "       0.00055994, 0.00055995, 0.00055995, 0.0015082 , 0.00153505,\n",
      "       0.00153524, 0.00164443, 0.00166659, 0.00166707, 0.00137771,\n",
      "       0.00142855, 0.00145398, 0.00094958, 0.00103263, 0.00108464,\n",
      "       0.00094958, 0.00103263, 0.00108464, 0.00088713, 0.00091504,\n",
      "       0.00096837, 0.00148165, 0.00148173, 0.00148173, 0.00150379,\n",
      "       0.00150384, 0.00150384, 0.00055535, 0.00055543, 0.00055543,\n",
      "       0.00140749, 0.00143114, 0.00143217, 0.00157196, 0.00159839,\n",
      "       0.00159929, 0.00135191, 0.00140764, 0.0014354 , 0.00089663,\n",
      "       0.00091697, 0.00093584, 0.00089663, 0.00091697, 0.00093584,\n",
      "       0.000836  , 0.0008055 , 0.00084559]), 'rank_test_score': array([237, 193,  32, 237, 193,  32, 236, 192,  31, 241, 211, 131, 241,\n",
      "       212, 139, 239, 210, 130, 233, 205, 142, 233, 205, 142, 233, 205,\n",
      "       141, 243, 215, 164, 230, 203, 134, 218, 191,  34, 232, 213, 165,\n",
      "       229, 209, 159, 226, 202, 124, 221, 198, 149, 221, 198, 149, 223,\n",
      "       200, 152, 240, 216, 173, 228, 204, 163, 217, 190,  35, 231, 214,\n",
      "       171, 227, 208, 162, 225, 201, 125, 219, 195, 145, 219, 195, 145,\n",
      "       224, 197, 151,  26,  23,  22,  27,  25,  24,  12,   5,   4,  63,\n",
      "        75,  78,  77,  94,  99,  42,  48,  58,  88, 128, 137,  88, 128,\n",
      "       137,  84, 110, 122,  64,  60,  59,  41,  40,  39,  21,  20,  19,\n",
      "        90, 109, 114,  83, 104, 115,  44,  43,  49, 119, 156, 174, 119,\n",
      "       156, 174, 117, 144, 170,  76,  71,  70,  69,  67,  68,  28,  29,\n",
      "        30,  96, 116, 121,  82,  95, 111,  46,  47,  51, 126, 168, 178,\n",
      "       126, 168, 178, 123, 158, 176,   8,   6,   7,  11,  10,   9,   3,\n",
      "         2,   1,  72,  73,  74,  97, 105, 107,  61,  65,  66, 132, 147,\n",
      "       154, 132, 147, 154, 118, 135, 140,  81,  79,  79,  38,  36,  36,\n",
      "        18,  17,  16,  92, 101, 102, 103, 112, 113,  50,  57,  62, 160,\n",
      "       180, 185, 160, 180, 185, 136, 172, 177,  87,  85,  85,  53,  54,\n",
      "        54,  13,  14,  14,  91,  98, 100,  93, 106, 108,  45,  52,  56,\n",
      "       166, 183, 187, 166, 183, 187, 153, 182, 189])}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, explained_variance_score, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('processed_data.csv')\n",
    "\n",
    "# Define feature columns and target column\n",
    "feature_columns = [col for col in data.columns if col not in ['datetime', 'price_log', 'price_boxcox', 'timezone']]\n",
    "target_column = 'price_log'\n",
    "\n",
    "# Separate features and target\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "\n",
    "# Preprocessing for numerical data: standard scaling\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing for categorical data: one-hot encoding\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Define the model\n",
    "model = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('model', model)])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 200, 300],\n",
    "    'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'model__max_depth': [3, 5, 7],\n",
    "    'model__min_samples_split': [2, 5, 10],\n",
    "    'model__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, \n",
    "                           cv=3, n_jobs=-1, scoring='neg_mean_squared_error', verbose=3)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "try:\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best parameters and the best model\n",
    "    best_params = grid_search.best_params_\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Make predictions with the best model\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Evaluate the best model\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    adjusted_r2 = 1 - (1 - r2) * (len(y_test) - 1) / (len(y_test) - X_test.shape[1] - 1)\n",
    "    explained_variance = explained_variance_score(y_test, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "    # Print the best parameters and evaluation metrics\n",
    "    print('Best Model Performance:')\n",
    "    print(f'Best Parameters: {best_params}')\n",
    "    print(f'Mean Squared Error (MSE): {mse}')\n",
    "    print(f'R-squared (RÂ²) Score: {r2}')\n",
    "    print(f'Adjusted R-squared: {adjusted_r2}')\n",
    "    print(f'Explained Variance Score: {explained_variance}')\n",
    "    print(f'Mean Absolute Percentage Error (MAPE): {mape}')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during GridSearchCV fitting: {e}\")\n",
    "\n",
    "# Additional debug information\n",
    "print(\"GridSearchCV fit status:\")\n",
    "print(grid_search.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
